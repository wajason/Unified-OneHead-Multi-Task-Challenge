{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1adc612a",
      "metadata": {
        "id": "1adc612a"
      },
      "outputs": [],
      "source": [
        "# @title Unified-OneHead Multi-Task Challenge Implementation\n",
        "# Install required libraries\n",
        "!pip install torch torchvision torchaudio fastscnn -q\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from fastscnn import FastSCNN\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Download and prepare datasets (simulated for this example)\n",
        "# Replace with actual download command from course\n",
        "!mkdir -p data/mini_coco_det/train data/mini_coco_det/val data/mini_voc_seg/train data/mini_voc_seg/val data/imagenette_160/train data/imagenette_160/val\n",
        "# Simulated data loading (replace with real data paths)\n",
        "class MultiTaskDataset(Dataset):\n",
        "    def __init__(self, data_dir, task, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.task = task\n",
        "        self.transform = transform\n",
        "        self.images = [os.path.join(data_dir, img) for img in os.listdir(data_dir) if img.endswith('.jpg')]\n",
        "        self.annotations = self._load_annotations()\n",
        "\n",
        "    def _load_annotations(self):\n",
        "        annotations = []\n",
        "        for img in self.images:\n",
        "            if self.task == 'det':\n",
        "                ann = {'boxes': np.random.rand(5, 4), 'labels': np.random.randint(0, 10, 5)}  # Simulated COCO JSON\n",
        "            elif self.task == 'seg':\n",
        "                ann = np.random.randint(0, 20, (512, 512))  # Simulated PNG mask\n",
        "            elif self.task == 'cls':\n",
        "                ann = np.random.randint(0, 10)  # Simulated class label\n",
        "            annotations.append(ann)\n",
        "        return annotations\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.annotations[idx]\n",
        "\n",
        "# Data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Datasets and DataLoaders\n",
        "train_datasets = {\n",
        "    'seg': MultiTaskDataset('data/mini_voc_seg/train', 'seg', transform),\n",
        "    'det': MultiTaskDataset('data/mini_coco_det/train', 'det', transform),\n",
        "    'cls': MultiTaskDataset('data/imagenette_160/train', 'cls', transform)\n",
        "}\n",
        "val_datasets = {\n",
        "    'seg': MultiTaskDataset('data/mini_voc_seg/val', 'seg', transform),\n",
        "    'det': MultiTaskDataset('data/mini_coco_det/val', 'det', transform),\n",
        "    'cls': MultiTaskDataset('data/imagenette_160/val', 'cls', transform)\n",
        "}\n",
        "train_loaders = {task: DataLoader(dataset, batch_size=8, shuffle=True) for task, dataset in train_datasets.items()}\n",
        "val_loaders = {task: DataLoader(dataset, batch_size=8, shuffle=False) for task, dataset in val_datasets.items()}\n",
        "\n",
        "# Model Definition\n",
        "class MultiTaskHead(nn.Module):\n",
        "    def __init__(self, in_channels=64):\n",
        "        super(MultiTaskHead, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 128, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.output = nn.Conv2d(64, 10 + 20 + 10, kernel_size=1)  # Det(10) + Seg(20) + Cls(10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.output(x)\n",
        "        det_out = x[:, :10, :, :]  # N x (cx, cy, w, h, conf, C_det)\n",
        "        seg_out = x[:, 10:30, :, :]  # C_seg x H x W\n",
        "        cls_out = x[:, 30:, :, :].mean([2, 3])  # C_cls logits\n",
        "        return det_out, seg_out, cls_out\n",
        "\n",
        "class UnifiedModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UnifiedModel, self).__init__()\n",
        "        self.backbone = FastSCNN(pretrained=True)\n",
        "        self.head = MultiTaskHead(in_channels=64)\n",
        "        self.fisher = {}  # For EWC\n",
        "        self.old_model = None  # For LwF and KD\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "        det_out, seg_out, cls_out = self.head(features)\n",
        "        return det_out, seg_out, cls_out\n",
        "\n",
        "model = UnifiedModel().to(device)\n",
        "\n",
        "# Loss Functions\n",
        "def compute_losses(outputs, targets, task):\n",
        "    det_out, seg_out, cls_out = outputs\n",
        "    if task == 'det':\n",
        "        # Simulated detection loss (e.g., IoU loss)\n",
        "        loss = nn.MSELoss()(det_out, torch.tensor(targets).to(device))\n",
        "    elif task == 'seg':\n",
        "        loss = nn.CrossEntropyLoss()(seg_out, torch.tensor(targets).to(device).long())\n",
        "    elif task == 'cls':\n",
        "        loss = nn.CrossEntropyLoss()(cls_out, torch.tensor(targets).to(device).long())\n",
        "    return loss\n",
        "\n",
        "# Forgetting Mitigation Tools\n",
        "def ewc_loss(model, task, fisher, old_params):\n",
        "    loss = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if name in fisher[task]:\n",
        "            loss += (fisher[task][name] * (param - old_params[name]).pow(2)).sum()\n",
        "    return loss * 0.1  # EWC penalty\n",
        "\n",
        "def lwf_loss(model, inputs, task, old_model):\n",
        "    with torch.no_grad():\n",
        "        old_det, old_seg, old_cls = old_model(inputs)\n",
        "    new_det, new_seg, new_cls = model(inputs)\n",
        "    loss = nn.KLDivLoss()(torch.log_softmax(new_det, dim=1), torch.softmax(old_det, dim=1)) + \\\n",
        "           nn.KLDivLoss()(torch.log_softmax(new_seg, dim=1), torch.softmax(old_seg, dim=1)) + \\\n",
        "           nn.KLDivLoss()(torch.log_softmax(new_cls, dim=1), torch.softmax(old_cls, dim=1))\n",
        "    return loss * 0.5\n",
        "\n",
        "def replay_buffer(model, dataloader, buffer_size=10):\n",
        "    buffer = []\n",
        "    for i, (inputs, targets) in enumerate(dataloader):\n",
        "        if len(buffer) >= buffer_size:\n",
        "            break\n",
        "        buffer.append((inputs.to(device), targets))\n",
        "    return buffer\n",
        "\n",
        "def knowledge_distillation(model, teacher_model, inputs):\n",
        "    with torch.no_grad():\n",
        "        teacher_det, teacher_seg, teacher_cls = teacher_model(inputs)\n",
        "    student_det, student_seg, student_cls = model(inputs)\n",
        "    loss = nn.MSELoss()(student_det, teacher_det) + nn.MSELoss()(student_seg, teacher_seg) + nn.MSELoss()(student_cls, teacher_cls)\n",
        "    return loss * 0.3\n",
        "\n",
        "# Advanced Strategies from Top-Tier Papers\n",
        "def pocl_optimization(model, task_loaders, memory):\n",
        "    # Pareto-Optimized CL (Wu et al., ICML 2024)\n",
        "    grads = {}\n",
        "    for task, loader in task_loaders.items():\n",
        "        for inputs, targets in loader:\n",
        "            inputs, targets = inputs.to(device), targets\n",
        "            outputs = model(inputs)\n",
        "            loss = compute_losses(outputs, targets, task)\n",
        "            grads[task] = torch.autograd.grad(loss, model.parameters())\n",
        "    # Simplified Pareto optimization (multi-objective balancing)\n",
        "    total_grad = torch.stack([g.sum() for g in grads.values()]).mean(dim=0)\n",
        "    return total_grad\n",
        "\n",
        "def self_synthesized_rehearsal(model, task, num_samples=10):\n",
        "    # Self-Synthesized Rehearsal (Huang et al., ACL 2024)\n",
        "    synthetic_inputs = torch.randn(num_samples, 3, 512, 512).to(device)\n",
        "    with torch.no_grad():\n",
        "        _, _, cls_out = model(synthetic_inputs)\n",
        "    synthetic_targets = cls_out.argmax(dim=1)\n",
        "    return synthetic_inputs, synthetic_targets\n",
        "\n",
        "# Training Loop\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "tasks = ['seg', 'det', 'cls']\n",
        "baselines = {}\n",
        "mitigation_methods = ['None', 'EWC', 'LwF', 'Replay', 'KD', 'POCL', 'SSR']\n",
        "\n",
        "for stage, task in enumerate(tasks):\n",
        "    print(f\"Training Stage {stage + 1}: {task}\")\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    if stage == 0:\n",
        "        model.old_model = None\n",
        "    else:\n",
        "        model.old_model = UnifiedModel().to(device)\n",
        "        model.old_model.load_state_dict(model.state_dict())\n",
        "\n",
        "    # Compute Fisher Information for EWC\n",
        "    if stage > 0 and 'EWC' in mitigation_methods:\n",
        "        for name, param in model.named_parameters():\n",
        "            model.fisher[task] = param.data.clone().detach()\n",
        "\n",
        "    for epoch in range(5):  # Adjust epochs to fit 2h limit\n",
        "        for inputs, targets in train_loaders[task]:\n",
        "            inputs, targets = inputs.to(device), targets\n",
        "            optimizer.zero_grad()\n",
        "            det_out, seg_out, cls_out = model(inputs)\n",
        "\n",
        "            task_loss = compute_losses((det_out, seg_out, cls_out), targets, task)\n",
        "            total_loss = task_loss\n",
        "\n",
        "            # Apply mitigation methods\n",
        "            method_losses = {}\n",
        "            if 'EWC' in mitigation_methods:\n",
        "                method_losses['EWC'] = ewc_loss(model, task, model.fisher, model.old_model.state_dict())\n",
        "                total_loss += method_losses['EWC']\n",
        "            if 'LwF' in mitigation_methods and model.old_model:\n",
        "                method_losses['LwF'] = lwf_loss(model, inputs, task, model.old_model)\n",
        "                total_loss += method_losses['LwF']\n",
        "            if 'Replay' in mitigation_methods:\n",
        "                buffer = replay_buffer(model, train_loaders[tasks[stage-1]], buffer_size=10)\n",
        "                replay_loss = sum(compute_losses(model(inputs), targets, tasks[stage-1]) for inputs, targets in buffer) / len(buffer)\n",
        "                method_losses['Replay'] = replay_loss\n",
        "                total_loss += method_losses['Replay']\n",
        "            if 'KD' in mitigation_methods and model.old_model:\n",
        "                method_losses['KD'] = knowledge_distillation(model, model.old_model, inputs)\n",
        "                total_loss += method_losses['KD']\n",
        "            if 'POCL' in mitigation_methods:\n",
        "                method_losses['POCL'] = pocl_optimization(model, {t: train_loaders[t] for t in tasks[:stage+1]}, None)\n",
        "                total_loss += method_losses['POCL']\n",
        "            if 'SSR' in mitigation_methods:\n",
        "                synth_inputs, synth_targets = self_synthesized_rehearsal(model, task)\n",
        "                ssr_loss = compute_losses(model(synth_inputs), synth_targets, task)\n",
        "                method_losses['SSR'] = ssr_loss\n",
        "                total_loss += method_losses['SSR']\n",
        "\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            metric = np.random.rand()  # Simulated mIoU/mAP/Top-1 (replace with real metrics)\n",
        "            if task not in baselines:\n",
        "                baselines[task] = metric\n",
        "            print(f\"Epoch {epoch+1}, {task} Metric: {metric:.4f}, Drop: {(baselines[task] - metric) / baselines[task] * 100:.2f}%\")\n",
        "\n",
        "    print(f\"Stage {stage + 1} completed in {time.time() - start_time:.2f}s\")\n",
        "\n",
        "# Evaluation\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    metrics = {'mIoU': 0, 'mAP': 0, 'Top-1': 0}\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            det_out, seg_out, cls_out = model(inputs)\n",
        "            # Simulated evaluation (replace with real metrics)\n",
        "            metrics['mIoU'] += np.random.rand()\n",
        "            metrics['mAP'] += np.random.rand()\n",
        "            metrics['Top-1'] += np.random.rand()\n",
        "    return {k: v / len(loader) for k, v in metrics.items()}\n",
        "\n",
        "for task, loader in val_loaders.items():\n",
        "    metrics = evaluate(model, loader)\n",
        "    drop = {(k, (baselines[task] - metrics[k]) / baselines[task] * 100) for k in metrics}\n",
        "    print(f\"{task} Evaluation: {metrics}, Drops: {drop}\")\n",
        "\n",
        "# Save model and results\n",
        "torch.save(model.state_dict(), 'your_model.pt')"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}