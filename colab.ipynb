{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 克隆 GitHub 倉庫並切換到目錄\n",
        "# 這會從你的 GitHub 倉庫下載資料，包括 data 資料夾\n",
        "\n",
        "!git clone https://github.com/wajason/Unified-OneHead-Multi-Task-Challenge.git\n",
        "%cd Unified-OneHead-Multi-Task-Challenge"
      ],
      "metadata": {
        "id": "5SaMWRreoGic",
        "outputId": "3959b419-ac30-4314-dbf1-07033efcf2bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5SaMWRreoGic",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Unified-OneHead-Multi-Task-Challenge'...\n",
            "remote: Enumerating objects: 1284, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 1284 (delta 4), reused 2 (delta 0), pack-reused 1273 (from 3)\u001b[K\n",
            "Receiving objects: 100% (1284/1284), 79.56 MiB | 46.71 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n",
            "/content/Unified-OneHead-Multi-Task-Challenge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R data"
      ],
      "metadata": {
        "id": "GGJ62h0UoMj7",
        "outputId": "ff294ca4-a0f5-48ca-ec28-1cb65b8a32d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GGJ62h0UoMj7",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data:\n",
            "imagenette_160\tmini_coco_det  mini_voc_seg\n",
            "\n",
            "data/imagenette_160:\n",
            "train  val\n",
            "\n",
            "data/imagenette_160/train:\n",
            "n01440764  n02979186  n03028079  n03417042  n03445777\n",
            "n02102040  n03000684  n03394916  n03425413  n03888257\n",
            "\n",
            "data/imagenette_160/train/n01440764:\n",
            "n01440764_105.JPEG  n01440764_237.JPEG\tn01440764_413.JPEG  n01440764_458.JPEG\n",
            "n01440764_107.JPEG  n01440764_239.JPEG\tn01440764_416.JPEG  n01440764_459.JPEG\n",
            "n01440764_137.JPEG  n01440764_315.JPEG\tn01440764_438.JPEG  n01440764_485.JPEG\n",
            "n01440764_148.JPEG  n01440764_334.JPEG\tn01440764_449.JPEG  n01440764_63.JPEG\n",
            "n01440764_188.JPEG  n01440764_36.JPEG\tn01440764_44.JPEG   n01440764_78.JPEG\n",
            "n01440764_18.JPEG   n01440764_39.JPEG\tn01440764_457.JPEG  n01440764_96.JPEG\n",
            "\n",
            "data/imagenette_160/train/n02102040:\n",
            "n02102040_107.JPEG  n02102040_139.JPEG\tn02102040_43.JPEG  n02102040_76.JPEG\n",
            "n02102040_108.JPEG  n02102040_148.JPEG\tn02102040_55.JPEG  n02102040_78.JPEG\n",
            "n02102040_113.JPEG  n02102040_149.JPEG\tn02102040_5.JPEG   n02102040_83.JPEG\n",
            "n02102040_114.JPEG  n02102040_153.JPEG\tn02102040_63.JPEG  n02102040_95.JPEG\n",
            "n02102040_118.JPEG  n02102040_35.JPEG\tn02102040_68.JPEG  n02102040_97.JPEG\n",
            "n02102040_127.JPEG  n02102040_37.JPEG\tn02102040_74.JPEG  n02102040_99.JPEG\n",
            "\n",
            "data/imagenette_160/train/n02979186:\n",
            "n02979186_174.JPEG  n02979186_228.JPEG\tn02979186_287.JPEG  n02979186_73.JPEG\n",
            "n02979186_184.JPEG  n02979186_229.JPEG\tn02979186_293.JPEG  n02979186_78.JPEG\n",
            "n02979186_198.JPEG  n02979186_237.JPEG\tn02979186_294.JPEG  n02979186_7.JPEG\n",
            "n02979186_205.JPEG  n02979186_254.JPEG\tn02979186_323.JPEG  n02979186_83.JPEG\n",
            "n02979186_213.JPEG  n02979186_258.JPEG\tn02979186_35.JPEG   n02979186_93.JPEG\n",
            "n02979186_216.JPEG  n02979186_268.JPEG\tn02979186_66.JPEG   n02979186_97.JPEG\n",
            "\n",
            "data/imagenette_160/train/n03000684:\n",
            "n03000684_119.JPEG  n03000684_228.JPEG\tn03000684_389.JPEG  n03000684_455.JPEG\n",
            "n03000684_154.JPEG  n03000684_293.JPEG\tn03000684_398.JPEG  n03000684_473.JPEG\n",
            "n03000684_157.JPEG  n03000684_337.JPEG\tn03000684_3.JPEG    n03000684_493.JPEG\n",
            "n03000684_16.JPEG   n03000684_365.JPEG\tn03000684_417.JPEG  n03000684_507.JPEG\n",
            "n03000684_176.JPEG  n03000684_368.JPEG\tn03000684_425.JPEG  n03000684_87.JPEG\n",
            "n03000684_225.JPEG  n03000684_37.JPEG\tn03000684_426.JPEG  n03000684_94.JPEG\n",
            "\n",
            "data/imagenette_160/train/n03028079:\n",
            "n03028079_166.JPEG  n03028079_237.JPEG\tn03028079_448.JPEG  n03028079_577.JPEG\n",
            "n03028079_167.JPEG  n03028079_265.JPEG\tn03028079_455.JPEG  n03028079_578.JPEG\n",
            "n03028079_176.JPEG  n03028079_27.JPEG\tn03028079_478.JPEG  n03028079_593.JPEG\n",
            "n03028079_198.JPEG  n03028079_364.JPEG\tn03028079_484.JPEG  n03028079_603.JPEG\n",
            "n03028079_206.JPEG  n03028079_39.JPEG\tn03028079_508.JPEG  n03028079_606.JPEG\n",
            "n03028079_236.JPEG  n03028079_419.JPEG\tn03028079_573.JPEG  n03028079_69.JPEG\n",
            "\n",
            "data/imagenette_160/train/n03394916:\n",
            "n03394916_109.JPEG   n03394916_1594.JPEG  n03394916_2257.JPEG\n",
            "n03394916_1109.JPEG  n03394916_1633.JPEG  n03394916_2324.JPEG\n",
            "n03394916_1149.JPEG  n03394916_1695.JPEG  n03394916_2376.JPEG\n",
            "n03394916_1163.JPEG  n03394916_1769.JPEG  n03394916_2688.JPEG\n",
            "n03394916_1165.JPEG  n03394916_1906.JPEG  n03394916_427.JPEG\n",
            "n03394916_1297.JPEG  n03394916_1915.JPEG  n03394916_59.JPEG\n",
            "n03394916_1326.JPEG  n03394916_1919.JPEG  n03394916_747.JPEG\n",
            "n03394916_1377.JPEG  n03394916_2043.JPEG  n03394916_896.JPEG\n",
            "\n",
            "data/imagenette_160/train/n03417042:\n",
            "n03417042_104.JPEG  n03417042_173.JPEG\tn03417042_256.JPEG  n03417042_459.JPEG\n",
            "n03417042_108.JPEG  n03417042_176.JPEG\tn03417042_265.JPEG  n03417042_495.JPEG\n",
            "n03417042_118.JPEG  n03417042_189.JPEG\tn03417042_274.JPEG  n03417042_518.JPEG\n",
            "n03417042_127.JPEG  n03417042_213.JPEG\tn03417042_303.JPEG  n03417042_53.JPEG\n",
            "n03417042_147.JPEG  n03417042_229.JPEG\tn03417042_356.JPEG  n03417042_79.JPEG\n",
            "n03417042_153.JPEG  n03417042_234.JPEG\tn03417042_366.JPEG  n03417042_94.JPEG\n",
            "\n",
            "data/imagenette_160/train/n03425413:\n",
            "n03425413_1055.JPEG  n03425413_1825.JPEG  n03425413_2637.JPEG\n",
            "n03425413_106.JPEG   n03425413_1829.JPEG  n03425413_2818.JPEG\n",
            "n03425413_1199.JPEG  n03425413_2055.JPEG  n03425413_287.JPEG\n",
            "n03425413_1214.JPEG  n03425413_2079.JPEG  n03425413_2953.JPEG\n",
            "n03425413_1284.JPEG  n03425413_2257.JPEG  n03425413_486.JPEG\n",
            "n03425413_145.JPEG   n03425413_2307.JPEG  n03425413_604.JPEG\n",
            "n03425413_1469.JPEG  n03425413_2354.JPEG  n03425413_729.JPEG\n",
            "n03425413_1769.JPEG  n03425413_2443.JPEG  n03425413_934.JPEG\n",
            "\n",
            "data/imagenette_160/train/n03445777:\n",
            "n03445777_127.JPEG  n03445777_153.JPEG\tn03445777_278.JPEG  n03445777_36.JPEG\n",
            "n03445777_129.JPEG  n03445777_189.JPEG\tn03445777_298.JPEG  n03445777_3.JPEG\n",
            "n03445777_136.JPEG  n03445777_193.JPEG\tn03445777_303.JPEG  n03445777_59.JPEG\n",
            "n03445777_138.JPEG  n03445777_237.JPEG\tn03445777_306.JPEG  n03445777_6.JPEG\n",
            "n03445777_143.JPEG  n03445777_24.JPEG\tn03445777_333.JPEG  n03445777_75.JPEG\n",
            "n03445777_147.JPEG  n03445777_258.JPEG\tn03445777_356.JPEG  n03445777_95.JPEG\n",
            "\n",
            "data/imagenette_160/train/n03888257:\n",
            "n03888257_1074.JPEG  n03888257_226.JPEG  n03888257_548.JPEG  n03888257_877.JPEG\n",
            "n03888257_1075.JPEG  n03888257_297.JPEG  n03888257_556.JPEG  n03888257_894.JPEG\n",
            "n03888257_1097.JPEG  n03888257_366.JPEG  n03888257_73.JPEG   n03888257_904.JPEG\n",
            "n03888257_128.JPEG   n03888257_383.JPEG  n03888257_78.JPEG   n03888257_936.JPEG\n",
            "n03888257_167.JPEG   n03888257_457.JPEG  n03888257_817.JPEG  n03888257_949.JPEG\n",
            "n03888257_18.JPEG    n03888257_48.JPEG\t n03888257_874.JPEG  n03888257_94.JPEG\n",
            "\n",
            "data/imagenette_160/val:\n",
            "n01440764  n02979186  n03028079  n03417042  n03445777\n",
            "n02102040  n03000684  n03394916  n03425413  n03888257\n",
            "\n",
            "data/imagenette_160/val/n01440764:\n",
            "n01440764_141.JPEG  n01440764_200.JPEG\tn01440764_292.JPEG\n",
            "n01440764_190.JPEG  n01440764_261.JPEG\tn01440764_320.JPEG\n",
            "\n",
            "data/imagenette_160/val/n02102040:\n",
            "n02102040_132.JPEG  n02102040_150.JPEG\tn02102040_182.JPEG\n",
            "n02102040_142.JPEG  n02102040_171.JPEG\tn02102040_30.JPEG\n",
            "\n",
            "data/imagenette_160/val/n02979186:\n",
            "n02979186_11.JPEG   n02979186_162.JPEG\tn02979186_40.JPEG\n",
            "n02979186_140.JPEG  n02979186_260.JPEG\tn02979186_70.JPEG\n",
            "\n",
            "data/imagenette_160/val/n03000684:\n",
            "n03000684_141.JPEG  n03000684_272.JPEG\tn03000684_41.JPEG\n",
            "n03000684_180.JPEG  n03000684_32.JPEG\tn03000684_82.JPEG\n",
            "\n",
            "data/imagenette_160/val/n03028079:\n",
            "n03028079_102.JPEG  n03028079_1.JPEG\tn03028079_332.JPEG\n",
            "n03028079_151.JPEG  n03028079_322.JPEG\tn03028079_80.JPEG\n",
            "\n",
            "data/imagenette_160/val/n03394916:\n",
            "n03394916_1091.JPEG  n03394916_180.JPEG  n03394916_292.JPEG\n",
            "n03394916_1130.JPEG  n03394916_230.JPEG  n03394916_540.JPEG\n",
            "\n",
            "data/imagenette_160/val/n03417042:\n",
            "n03417042_11.JPEG   n03417042_22.JPEG  n03417042_90.JPEG\n",
            "n03417042_130.JPEG  n03417042_30.JPEG  n03417042_91.JPEG\n",
            "\n",
            "data/imagenette_160/val/n03425413:\n",
            "n03425413_1342.JPEG  n03425413_212.JPEG  n03425413_652.JPEG\n",
            "n03425413_1351.JPEG  n03425413_260.JPEG  n03425413_732.JPEG\n",
            "\n",
            "data/imagenette_160/val/n03445777:\n",
            "n03445777_101.JPEG  n03445777_172.JPEG\tn03445777_70.JPEG\n",
            "n03445777_110.JPEG  n03445777_200.JPEG\tn03445777_71.JPEG\n",
            "\n",
            "data/imagenette_160/val/n03888257:\n",
            "n03888257_121.JPEG  n03888257_142.JPEG\tn03888257_42.JPEG\n",
            "n03888257_12.JPEG   n03888257_171.JPEG\tn03888257_80.JPEG\n",
            "\n",
            "data/mini_coco_det:\n",
            "train  val\n",
            "\n",
            "data/mini_coco_det/train:\n",
            "data  labels.json\n",
            "\n",
            "data/mini_coco_det/train/data:\n",
            "000000001584.jpg  000000155885.jpg  000000293794.jpg  000000438907.jpg\n",
            "000000002685.jpg  000000156416.jpg  000000295138.jpg  000000442746.jpg\n",
            "000000013729.jpg  000000159399.jpg  000000296231.jpg  000000444444.jpg\n",
            "000000013923.jpg  000000161925.jpg  000000297595.jpg  000000446409.jpg\n",
            "000000014380.jpg  000000162581.jpg  000000299319.jpg  000000447088.jpg\n",
            "000000016249.jpg  000000163682.jpg  000000302030.jpg  000000450686.jpg\n",
            "000000018833.jpg  000000169996.jpg  000000305343.jpg  000000451308.jpg\n",
            "000000019221.jpg  000000172330.jpg  000000309655.jpg  000000453756.jpg\n",
            "000000025424.jpg  000000173091.jpg  000000313562.jpg  000000455937.jpg\n",
            "000000026204.jpg  000000173302.jpg  000000314154.jpg  000000456292.jpg\n",
            "000000026690.jpg  000000173704.jpg  000000315001.jpg  000000456559.jpg\n",
            "000000029187.jpg  000000176037.jpg  000000317433.jpg  000000457884.jpg\n",
            "000000031118.jpg  000000176799.jpg  000000323751.jpg  000000459153.jpg\n",
            "000000033638.jpg  000000176857.jpg  000000326627.jpg  000000459195.jpg\n",
            "000000034417.jpg  000000179141.jpg  000000329717.jpg  000000461063.jpg\n",
            "000000035197.jpg  000000180011.jpg  000000331799.jpg  000000462031.jpg\n",
            "000000036936.jpg  000000181449.jpg  000000334007.jpg  000000463633.jpg\n",
            "000000037777.jpg  000000181753.jpg  000000337987.jpg  000000464251.jpg\n",
            "000000045070.jpg  000000182162.jpg  000000338948.jpg  000000466211.jpg\n",
            "000000047571.jpg  000000182417.jpg  000000341921.jpg  000000470924.jpg\n",
            "000000047585.jpg  000000186422.jpg  000000345941.jpg  000000480122.jpg\n",
            "000000047740.jpg  000000188465.jpg  000000346207.jpg  000000482436.jpg\n",
            "000000054592.jpg  000000190841.jpg  000000349860.jpg  000000487159.jpg\n",
            "000000057232.jpg  000000191288.jpg  000000350054.jpg  000000492968.jpg\n",
            "000000060102.jpg  000000191672.jpg  000000351053.jpg  000000497312.jpg\n",
            "000000062355.jpg  000000193565.jpg  000000354753.jpg  000000509014.jpg\n",
            "000000066412.jpg  000000194716.jpg  000000361586.jpg  000000511204.jpg\n",
            "000000069213.jpg  000000197658.jpg  000000364636.jpg  000000513567.jpg\n",
            "000000069577.jpg  000000204871.jpg  000000364884.jpg  000000513681.jpg\n",
            "000000070229.jpg  000000206411.jpg  000000368900.jpg  000000514797.jpg\n",
            "000000073702.jpg  000000209530.jpg  000000370486.jpg  000000521259.jpg\n",
            "000000078404.jpg  000000210273.jpg  000000379332.jpg  000000524850.jpg\n",
            "000000078748.jpg  000000213445.jpg  000000381587.jpg  000000526728.jpg\n",
            "000000079229.jpg  000000213830.jpg  000000383339.jpg  000000529122.jpg\n",
            "000000084674.jpg  000000219485.jpg  000000383406.jpg  000000530470.jpg\n",
            "000000085157.jpg  000000222559.jpg  000000384012.jpg  000000532058.jpg\n",
            "000000086483.jpg  000000222735.jpg  000000384136.jpg  000000536831.jpg\n",
            "000000086956.jpg  000000224861.jpg  000000384808.jpg  000000537153.jpg\n",
            "000000087199.jpg  000000225184.jpg  000000389624.jpg  000000542510.jpg\n",
            "000000088485.jpg  000000227227.jpg  000000389684.jpg  000000546626.jpg\n",
            "000000089697.jpg  000000229216.jpg  000000390246.jpg  000000550349.jpg\n",
            "000000090956.jpg  000000230993.jpg  000000390902.jpg  000000551439.jpg\n",
            "000000092091.jpg  000000231549.jpg  000000391722.jpg  000000554328.jpg\n",
            "000000097994.jpg  000000233238.jpg  000000393838.jpg  000000559665.jpg\n",
            "000000098392.jpg  000000236189.jpg  000000399655.jpg  000000561009.jpg\n",
            "000000099024.jpg  000000236308.jpg  000000399851.jpg  000000561256.jpg\n",
            "000000100428.jpg  000000237118.jpg  000000400161.jpg  000000562243.jpg\n",
            "000000108094.jpg  000000251140.jpg  000000401991.jpg  000000563702.jpg\n",
            "000000109118.jpg  000000252776.jpg  000000407614.jpg  000000563964.jpg\n",
            "000000121586.jpg  000000253386.jpg  000000411817.jpg  000000565962.jpg\n",
            "000000133000.jpg  000000253819.jpg  000000414170.jpg  000000568195.jpg\n",
            "000000133244.jpg  000000257478.jpg  000000417632.jpg  000000568814.jpg\n",
            "000000137727.jpg  000000258388.jpg  000000418696.jpg  000000572900.jpg\n",
            "000000138115.jpg  000000259854.jpg  000000422998.jpg  000000573349.jpg\n",
            "000000138492.jpg  000000263966.jpg  000000424975.jpg  000000575081.jpg\n",
            "000000144784.jpg  000000267300.jpg  000000427997.jpg  000000578871.jpg\n",
            "000000146831.jpg  000000269932.jpg  000000428111.jpg  000000579003.jpg\n",
            "000000150649.jpg  000000273715.jpg  000000432553.jpg  000000579655.jpg\n",
            "000000151480.jpg  000000281687.jpg  000000434204.jpg  000000579818.jpg\n",
            "000000154718.jpg  000000288584.jpg  000000437898.jpg  000000579902.jpg\n",
            "\n",
            "data/mini_coco_det/val:\n",
            "data  labels.json\n",
            "\n",
            "data/mini_coco_det/val/data:\n",
            "000000056545.jpg  000000213171.jpg  000000303305.jpg  000000389532.jpg\n",
            "000000068093.jpg  000000222825.jpg  000000304812.jpg  000000398810.jpg\n",
            "000000079380.jpg  000000224757.jpg  000000322944.jpg  000000415716.jpg\n",
            "000000092053.jpg  000000226984.jpg  000000323751.jpg  000000428111.jpg\n",
            "000000093201.jpg  000000240940.jpg  000000324258.jpg  000000434479.jpg\n",
            "000000105923.jpg  000000255917.jpg  000000341094.jpg  000000456015.jpg\n",
            "000000128748.jpg  000000257370.jpg  000000343496.jpg  000000476215.jpg\n",
            "000000140556.jpg  000000260105.jpg  000000346968.jpg  000000478721.jpg\n",
            "000000158227.jpg  000000261062.jpg  000000350679.jpg  000000507667.jpg\n",
            "000000161032.jpg  000000271177.jpg  000000353970.jpg  000000511204.jpg\n",
            "000000170099.jpg  000000279730.jpg  000000366611.jpg  000000513567.jpg\n",
            "000000181421.jpg  000000296649.jpg  000000370486.jpg  000000520707.jpg\n",
            "000000183709.jpg  000000297022.jpg  000000383842.jpg  000000540174.jpg\n",
            "000000196754.jpg  000000298396.jpg  000000384670.jpg  000000559160.jpg\n",
            "000000212704.jpg  000000301563.jpg  000000386457.jpg  000000575187.jpg\n",
            "\n",
            "data/mini_voc_seg:\n",
            "train  val\n",
            "\n",
            "data/mini_voc_seg/train:\n",
            "2007_000250.jpg  2008_000391.jpg  2009_001363.jpg  2010_003062.jpg\n",
            "2007_000250.png  2008_000391.png  2009_001363.png  2010_003062.png\n",
            "2007_000504.jpg  2008_000540.jpg  2009_001690.jpg  2010_003239.jpg\n",
            "2007_000504.png  2008_000540.png  2009_001690.png  2010_003239.png\n",
            "2007_000515.jpg  2008_000645.jpg  2009_001735.jpg  2010_003252.jpg\n",
            "2007_000515.png  2008_000645.png  2009_001735.png  2010_003252.png\n",
            "2007_000904.jpg  2008_000711.jpg  2009_001775.jpg  2010_003269.jpg\n",
            "2007_000904.png  2008_000711.png  2009_001775.png  2010_003269.png\n",
            "2007_001288.jpg  2008_000782.jpg  2009_002035.jpg  2010_003409.jpg\n",
            "2007_001288.png  2008_000782.png  2009_002035.png  2010_003409.png\n",
            "2007_001321.jpg  2008_001188.jpg  2009_002072.jpg  2010_003506.jpg\n",
            "2007_001321.png  2008_001188.png  2009_002072.png  2010_003506.png\n",
            "2007_001408.jpg  2008_001235.jpg  2009_002165.jpg  2010_003680.jpg\n",
            "2007_001408.png  2008_001235.png  2009_002165.png  2010_003680.png\n",
            "2007_001458.jpg  2008_001260.jpg  2009_002185.jpg  2010_003854.jpg\n",
            "2007_001458.png  2008_001260.png  2009_002185.png  2010_003854.png\n",
            "2007_001678.jpg  2008_001404.jpg  2009_002317.jpg  2010_004069.jpg\n",
            "2007_001678.png  2008_001404.png  2009_002317.png  2010_004069.png\n",
            "2007_001761.jpg  2008_001592.jpg  2009_002366.jpg  2010_004071.jpg\n",
            "2007_001761.png  2008_001592.png  2009_002366.png  2010_004071.png\n",
            "2007_002142.jpg  2008_001716.jpg  2009_002372.jpg  2010_004072.jpg\n",
            "2007_002142.png  2008_001716.png  2009_002372.png  2010_004072.png\n",
            "2007_002284.jpg  2008_001787.jpg  2009_002387.jpg  2010_004109.jpg\n",
            "2007_002284.png  2008_001787.png  2009_002387.png  2010_004109.png\n",
            "2007_002619.jpg  2008_001876.jpg  2009_002460.jpg  2010_004119.jpg\n",
            "2007_002619.png  2008_001876.png  2009_002460.png  2010_004119.png\n",
            "2007_002624.jpg  2008_001971.jpg  2009_002584.jpg  2010_004149.jpg\n",
            "2007_002624.png  2008_001971.png  2009_002584.png  2010_004149.png\n",
            "2007_002760.jpg  2008_001997.jpg  2009_002749.jpg  2010_004154.jpg\n",
            "2007_002760.png  2008_001997.png  2009_002749.png  2010_004154.png\n",
            "2007_002914.jpg  2008_002175.jpg  2009_002885.jpg  2010_004226.jpg\n",
            "2007_002914.png  2008_002175.png  2009_002885.png  2010_004226.png\n",
            "2007_003188.jpg  2008_002239.jpg  2009_002912.jpg  2010_004283.jpg\n",
            "2007_003188.png  2008_002239.png  2009_002912.png  2010_004283.png\n",
            "2007_003190.jpg  2008_002288.jpg  2009_002993.jpg  2010_004369.jpg\n",
            "2007_003190.png  2008_002288.png  2009_002993.png  2010_004369.png\n",
            "2007_003373.jpg  2008_002358.jpg  2009_003063.jpg  2010_004616.jpg\n",
            "2007_003373.png  2008_002358.png  2009_003063.png  2010_004616.png\n",
            "2007_003872.jpg  2008_002710.jpg  2009_003304.jpg  2010_004789.jpg\n",
            "2007_003872.png  2008_002710.png  2009_003304.png  2010_004789.png\n",
            "2007_004003.jpg  2008_002775.jpg  2009_003494.jpg  2010_004825.jpg\n",
            "2007_004003.png  2008_002775.png  2009_003494.png  2010_004825.png\n",
            "2007_004241.jpg  2008_003333.jpg  2009_003569.jpg  2010_004946.jpg\n",
            "2007_004241.png  2008_003333.png  2009_003569.png  2010_004946.png\n",
            "2007_004380.jpg  2008_003451.jpg  2009_003804.jpg  2010_004948.jpg\n",
            "2007_004380.png  2008_003451.png  2009_003804.png  2010_004948.png\n",
            "2007_004468.jpg  2008_003814.jpg  2009_003865.jpg  2010_004951.jpg\n",
            "2007_004468.png  2008_003814.png  2009_003865.png  2010_004951.png\n",
            "2007_004510.jpg  2008_004026.jpg  2009_003895.jpg  2010_004960.jpg\n",
            "2007_004510.png  2008_004026.png  2009_003895.png  2010_004960.png\n",
            "2007_004951.jpg  2008_004097.jpg  2009_003991.jpg  2010_004980.jpg\n",
            "2007_004951.png  2008_004097.png  2009_003991.png  2010_004980.png\n",
            "2007_005296.jpg  2008_004776.jpg  2009_004434.jpg  2010_005016.jpg\n",
            "2007_005296.png  2008_004776.png  2009_004434.png  2010_005016.png\n",
            "2007_005428.jpg  2008_005367.jpg  2009_004446.jpg  2010_005719.jpg\n",
            "2007_005428.png  2008_005367.png  2009_004446.png  2010_005719.png\n",
            "2007_005702.jpg  2008_005628.jpg  2009_004568.jpg  2010_005805.jpg\n",
            "2007_005702.png  2008_005628.png  2009_004568.png  2010_005805.png\n",
            "2007_006046.jpg  2008_005642.jpg  2009_004790.jpg  2010_005830.jpg\n",
            "2007_006046.png  2008_005642.png  2009_004790.png  2010_005830.png\n",
            "2007_006400.jpg  2008_005668.jpg  2009_004859.jpg  2011_000122.jpg\n",
            "2007_006400.png  2008_005668.png  2009_004859.png  2011_000122.png\n",
            "2007_006444.jpg  2008_006036.jpg  2009_004994.jpg  2011_000258.jpg\n",
            "2007_006444.png  2008_006036.png  2009_004994.png  2011_000258.png\n",
            "2007_006530.jpg  2008_006143.jpg  2009_005190.jpg  2011_000455.jpg\n",
            "2007_006530.png  2008_006143.png  2009_005190.png  2011_000455.png\n",
            "2007_006641.jpg  2008_006748.jpg  2010_000063.jpg  2011_000457.jpg\n",
            "2007_006641.png  2008_006748.png  2010_000063.png  2011_000457.png\n",
            "2007_006698.jpg  2008_006835.jpg  2010_000159.jpg  2011_000513.jpg\n",
            "2007_006698.png  2008_006835.png  2010_000159.png  2011_000513.png\n",
            "2007_006841.jpg  2008_007011.jpg  2010_000285.jpg  2011_000550.jpg\n",
            "2007_006841.png  2008_007011.png  2010_000285.png  2011_000550.png\n",
            "2007_007109.jpg  2008_007375.jpg  2010_000567.jpg  2011_000642.jpg\n",
            "2007_007109.png  2008_007375.png  2010_000567.png  2011_000642.png\n",
            "2007_007130.jpg  2008_007677.jpg  2010_000632.jpg  2011_000713.jpg\n",
            "2007_007130.png  2008_007677.png  2010_000632.png  2011_000713.png\n",
            "2007_007165.jpg  2008_007691.jpg  2010_000815.jpg  2011_000768.jpg\n",
            "2007_007165.png  2008_007691.png  2010_000815.png  2011_000768.png\n",
            "2007_007211.jpg  2008_007759.jpg  2010_000904.jpg  2011_000900.jpg\n",
            "2007_007211.png  2008_007759.png  2010_000904.png  2011_000900.png\n",
            "2007_007415.jpg  2008_007814.jpg  2010_001000.jpg  2011_001020.jpg\n",
            "2007_007415.png  2008_007814.png  2010_001000.png  2011_001020.png\n",
            "2007_007493.jpg  2008_008051.jpg  2010_001184.jpg  2011_001166.jpg\n",
            "2007_007493.png  2008_008051.png  2010_001184.png  2011_001166.png\n",
            "2007_007498.jpg  2009_000074.jpg  2010_001245.jpg  2011_001412.jpg\n",
            "2007_007498.png  2009_000074.png  2010_001245.png  2011_001412.png\n",
            "2007_007878.jpg  2009_000136.jpg  2010_001327.jpg  2011_001416.jpg\n",
            "2007_007878.png  2009_000136.png  2010_001327.png  2011_001416.png\n",
            "2007_008218.jpg  2009_000177.jpg  2010_001448.jpg  2011_001432.jpg\n",
            "2007_008218.png  2009_000177.png  2010_001448.png  2011_001432.png\n",
            "2007_008260.jpg  2009_000400.jpg  2010_001451.jpg  2011_001534.jpg\n",
            "2007_008260.png  2009_000400.png  2010_001451.png  2011_001534.png\n",
            "2007_008670.jpg  2009_000405.jpg  2010_001577.jpg  2011_001748.jpg\n",
            "2007_008670.png  2009_000405.png  2010_001577.png  2011_001748.png\n",
            "2007_008801.jpg  2009_000420.jpg  2010_001630.jpg  2011_001793.jpg\n",
            "2007_008801.png  2009_000420.png  2010_001630.png  2011_001793.png\n",
            "2007_008802.jpg  2009_000628.jpg  2010_001768.jpg  2011_001875.jpg\n",
            "2007_008802.png  2009_000628.png  2010_001768.png  2011_001875.png\n",
            "2007_009245.jpg  2009_000716.jpg  2010_002054.jpg  2011_001924.jpg\n",
            "2007_009245.png  2009_000716.png  2010_002054.png  2011_001924.png\n",
            "2007_009258.jpg  2009_000732.jpg  2010_002218.jpg  2011_001972.jpg\n",
            "2007_009258.png  2009_000732.png  2010_002218.png  2011_001972.png\n",
            "2007_009527.jpg  2009_000825.jpg  2010_002286.jpg  2011_002150.jpg\n",
            "2007_009527.png  2009_000825.png  2010_002286.png  2011_002150.png\n",
            "2007_009654.jpg  2009_000839.jpg  2010_002305.jpg  2011_002389.jpg\n",
            "2007_009654.png  2009_000839.png  2010_002305.png  2011_002389.png\n",
            "2007_009764.jpg  2009_000919.jpg  2010_002418.jpg  2011_002457.jpg\n",
            "2007_009764.png  2009_000919.png  2010_002418.png  2011_002457.png\n",
            "2007_009788.jpg  2009_000991.jpg  2010_002422.jpg  2011_002504.jpg\n",
            "2007_009788.png  2009_000991.png  2010_002422.png  2011_002504.png\n",
            "2007_009897.jpg  2009_001036.jpg  2010_002551.jpg  2011_002561.jpg\n",
            "2007_009897.png  2009_001036.png  2010_002551.png  2011_002561.png\n",
            "2007_009899.jpg  2009_001070.jpg  2010_002815.jpg  2011_002592.jpg\n",
            "2007_009899.png  2009_001070.png  2010_002815.png  2011_002592.png\n",
            "2008_000120.jpg  2009_001251.jpg  2010_002838.jpg  2011_002675.jpg\n",
            "2008_000120.png  2009_001251.png  2010_002838.png  2011_002675.png\n",
            "2008_000162.jpg  2009_001264.jpg  2010_002902.jpg  2011_002717.jpg\n",
            "2008_000162.png  2009_001264.png  2010_002902.png  2011_002717.png\n",
            "2008_000365.jpg  2009_001339.jpg  2010_002929.jpg  2011_003055.jpg\n",
            "2008_000365.png  2009_001339.png  2010_002929.png  2011_003055.png\n",
            "\n",
            "data/mini_voc_seg/val:\n",
            "2007_001154.jpg  2008_004363.jpg  2009_002914.jpg  2010_004543.jpg\n",
            "2007_001154.png  2008_004363.png  2009_002914.png  2010_004543.png\n",
            "2007_002378.jpg  2008_005089.jpg  2009_003369.jpg  2010_004916.jpg\n",
            "2007_002378.png  2008_005089.png  2009_003369.png  2010_004916.png\n",
            "2007_003604.jpg  2008_005266.jpg  2009_003857.jpg  2010_005021.jpg\n",
            "2007_003604.png  2008_005266.png  2009_003857.png  2010_005021.png\n",
            "2007_004033.jpg  2008_006159.jpg  2009_003928.jpg  2010_005891.jpg\n",
            "2007_004033.png  2008_006159.png  2009_003928.png  2010_005891.png\n",
            "2007_006028.jpg  2008_006327.jpg  2009_004091.jpg  2010_005951.jpg\n",
            "2007_006028.png  2008_006327.png  2009_004091.png  2010_005951.png\n",
            "2007_009630.jpg  2008_006986.jpg  2009_004248.jpg  2010_006009.jpg\n",
            "2007_009630.png  2008_006986.png  2009_004248.png  2010_006009.png\n",
            "2008_000238.jpg  2008_007031.jpg  2010_000174.jpg  2010_006034.jpg\n",
            "2008_000238.png  2008_007031.png  2010_000174.png  2010_006034.png\n",
            "2008_000696.jpg  2009_001008.jpg  2010_000269.jpg  2011_000003.jpg\n",
            "2008_000696.png  2009_001008.png  2010_000269.png  2011_000003.png\n",
            "2008_000848.jpg  2009_002164.jpg  2010_002254.jpg  2011_000226.jpg\n",
            "2008_000848.png  2009_002164.png  2010_002254.png  2011_000226.png\n",
            "2008_001119.jpg  2009_002221.jpg  2010_002778.jpg  2011_000419.jpg\n",
            "2008_001119.png  2009_002221.png  2010_002778.png  2011_000419.png\n",
            "2008_001137.jpg  2009_002291.jpg  2010_002907.jpg  2011_001071.jpg\n",
            "2008_001137.png  2009_002291.png  2010_002907.png  2011_001071.png\n",
            "2008_001498.jpg  2009_002320.jpg  2010_003599.jpg  2011_002119.jpg\n",
            "2008_001498.png  2009_002320.png  2010_003599.png  2011_002119.png\n",
            "2008_002681.jpg  2009_002419.jpg  2010_003894.jpg  2011_002200.jpg\n",
            "2008_002681.png  2009_002419.png  2010_003894.png  2011_002200.png\n",
            "2008_003330.jpg  2009_002727.jpg  2010_003958.jpg  2011_002447.jpg\n",
            "2008_003330.png  2009_002727.png  2010_003958.png  2011_002447.png\n",
            "2008_004172.jpg  2009_002856.jpg  2010_004499.jpg  2011_002770.jpg\n",
            "2008_004172.png  2009_002856.png  2010_004499.png  2011_002770.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Unified-OneHead Multi-Task Challenge Implementation\n",
        "# 安裝所需庫\n",
        "# 這裡只安裝 torch、torchvision 和 torchaudio，因為 fastscnn 無法直接用 pip 安裝，我們改用 mobilenet_v2\n",
        "!pip install torch torchvision torchaudio -q\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# 設定設備\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "vzoVFssDrq-9"
      },
      "id": "vzoVFssDrq-9",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/mini_coco_det/train/data/*.jpg | wc -l"
      ],
      "metadata": {
        "id": "Zm304C3CuJLN",
        "outputId": "9911a255-c486-4ab7-ba2f-1c12412122e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Zm304C3CuJLN",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "1adc612a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "1adc612a",
        "outputId": "dad0b4ff-84a5-4ba7-d1d7-67b50e134f6c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/imagenette_160_val/val'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-72bafba77a1c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;34m'det'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMultiTaskDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/mini_coco_det/val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'det'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;34m'seg'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMultiTaskDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/mini_voc_seg/val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0;34m'cls'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMultiTaskDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/imagenette_160_val/val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cls'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m }\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-72bafba77a1c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, task, transform)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cls'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mlabel_dirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mlabel_to_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/imagenette_160_val/val'"
          ]
        }
      ],
      "source": [
        "class MultiTaskDataset(Dataset):\n",
        "    def __init__(self, data_dir, task, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.task = task\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.annotations = []\n",
        "\n",
        "        if task == 'det':\n",
        "            labels_path = os.path.join(data_dir, 'labels.json')\n",
        "            if not os.path.exists(labels_path):\n",
        "                raise FileNotFoundError(f\"找不到 {labels_path}，請確認檔案是否存在！\")\n",
        "\n",
        "            with open(labels_path, 'r') as f:\n",
        "                labels_data = json.load(f)\n",
        "\n",
        "            image_dir = os.path.join(data_dir, 'data')\n",
        "            image_files = sorted([img for img in os.listdir(image_dir) if img.endswith(('.jpg', '.jpeg', '.JPEG'))])\n",
        "            image_file_set = set(image_files)\n",
        "\n",
        "            valid_images = {img['id']: img['file_name'] for img in labels_data['images'] if img['file_name'] in image_file_set}\n",
        "\n",
        "            ann_dict = {}\n",
        "            for ann in labels_data['annotations']:\n",
        "                img_id = ann['image_id']\n",
        "                if img_id in valid_images:\n",
        "                    if img_id not in ann_dict:\n",
        "                        ann_dict[img_id] = []\n",
        "                    ann_dict[img_id].append({\n",
        "                        'boxes': ann['bbox'],\n",
        "                        'labels': ann['category_id']\n",
        "                    })\n",
        "\n",
        "            for img_id, file_name in valid_images.items():\n",
        "                full_path = os.path.join(image_dir, file_name)\n",
        "                if img_id in ann_dict:\n",
        "                    self.images.append(full_path)\n",
        "                    self.annotations.append(ann_dict[img_id])\n",
        "\n",
        "        elif task == 'seg':\n",
        "            image_files = sorted([img for img in os.listdir(data_dir) if img.endswith(('.jpg', '.jpeg', '.JPEG'))])\n",
        "            for img in image_files:\n",
        "                img_path = os.path.join(data_dir, img)\n",
        "                mask_path = os.path.join(data_dir, img.replace('.jpg', '.png').replace('.jpeg', '.png').replace('.JPEG', '.png'))\n",
        "                if os.path.exists(mask_path):\n",
        "                    self.images.append(img_path)\n",
        "                    self.annotations.append(mask_path)\n",
        "\n",
        "        elif task == 'cls':\n",
        "            label_dirs = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
        "            label_to_index = {label: idx for idx, label in enumerate(label_dirs)}\n",
        "\n",
        "            for label in label_dirs:\n",
        "                label_path = os.path.join(data_dir, label)\n",
        "                for root, _, files in os.walk(label_path):\n",
        "                    for img in files:\n",
        "                        if img.endswith(('.jpg', '.jpeg', '.JPEG')):\n",
        "                            img_path = os.path.join(root, img)\n",
        "                            self.images.append(img_path)\n",
        "                            self.annotations.append(label_to_index[label])\n",
        "\n",
        "        if len(self.images) == 0:\n",
        "            raise ValueError(f\"在 {data_dir} 中未找到任何資料，請檢查資料結構！\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.task == 'seg':\n",
        "            mask = Image.open(self.annotations[idx]).convert('L')\n",
        "            # Ensure image and mask are the same size before transform\n",
        "            mask = mask.resize(img.size, Image.Resampling.NEAREST)\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "                # Apply transform to mask separately, but only resize and to tensor\n",
        "                mask_transform = transforms.Compose([\n",
        "                    transforms.Resize((512, 512), interpolation=Image.Resampling.NEAREST),\n",
        "                    transforms.ToTensor()\n",
        "                ])\n",
        "                mask = mask_transform(mask)\n",
        "            return img, mask.squeeze(0).long()  # Remove channel dimension for segmentation\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.task == 'det':\n",
        "            ann = self.annotations[idx]\n",
        "            boxes = torch.tensor([a['boxes'] for a in ann], dtype=torch.float32)\n",
        "            labels = torch.tensor([a['labels'] for a in ann], dtype=torch.long)\n",
        "            return img, {'boxes': boxes, 'labels': labels}\n",
        "\n",
        "        elif self.task == 'cls':\n",
        "            return img, torch.tensor(self.annotations[idx], dtype=torch.long)\n",
        "\n",
        "# Define consistent transform\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512), interpolation=Image.Resampling.BILINEAR),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_datasets = {\n",
        "    'det': MultiTaskDataset('data/mini_coco_det/train', 'det', image_transform),\n",
        "    'seg': MultiTaskDataset('data/mini_voc_seg/train', 'seg', image_transform),\n",
        "    'cls': MultiTaskDataset('data/imagenette_160/train', 'cls', image_transform)\n",
        "}\n",
        "\n",
        "val_datasets = {\n",
        "    'det': MultiTaskDataset('data/mini_coco_det/val', 'det', image_transform),\n",
        "    'seg': MultiTaskDataset('data/mini_voc_seg/val', 'seg', image_transform),\n",
        "    'cls': MultiTaskDataset('data/imagenette_160_val/val', 'cls', image_transform)\n",
        "}\n",
        "\n",
        "# Use a custom collate function to handle variable-sized targets\n",
        "def custom_collate(batch):\n",
        "    images = torch.stack([item[0] in batch for item in batch])\n",
        "    targets = [item[1] for item in batch]\n",
        "    return images, targets\n",
        "\n",
        "train_loaders = {task: DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=custom_collate if task == 'det' else None) for task, dataset in train_datasets.items()}\n",
        "val_loaders = {task: DataLoader(dataset, batch_size=8, shuffle=False, collate_fn=custom_collate if task == 'det' else None) for task, dataset in val_datasets.items()}\n",
        "\n",
        "class MultiTaskHead(nn.Module):\n",
        "    def __init__(self, in_channels=1280):\n",
        "        super(MultiTaskHead, self).__init__()\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.det_head = nn.Conv2d(64, 4 + 2, kernel_size=1)  # Adjusted for boxes (4) + confidence scores (2)\n",
        "        self.seg_head = nn.Conv2d(64, 20, kernel_size=1),  # 20 classes for segmentation\n",
        "        self.cls_head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64, 10)  # 10 classes for classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.shared(x)\n",
        "        det_out = self.det_head(x)  # [batch, 6, H, W]\n",
        "        seg_out = self.seg_head(x)  # [batch, 20, H, W]\n",
        "        cls_out = self.cls_head(x)  # [batch, 10]\n",
        "        return det_out, seg_out, cls_out\n",
        "\n",
        "class UnifiedModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UnifiedModel, self).__init__()\n",
        "        self.backbone = models.mobilenet_v2(pretrained=True).features\n",
        "        self.head = MultiTaskHead(in_channels=1280)\n",
        "        self.fisher = {}\n",
        "        self.old_model = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "        det_out, seg_out, cls_out = self.head(features)\n",
        "        return det_out, seg_out, cls_out\n",
        "\n",
        "model = UnifiedModel().to(device)\n",
        "\n",
        "# Define loss functions\n",
        "def compute_losses(outputs, targets, task):\n",
        "    det_out, seg_out, cls_out = outputs\n",
        "\n",
        "    if task == 'det':\n",
        "        # Detection loss (simplified for demonstration)\n",
        "        boxes_pred = det_out.permute(0, 2, 3, 1)  # [batch, H, W, W, 6]\n",
        "        loss = 0\n",
        "        for i in range(len(targets)):\n",
        "            target_boxes = targets[i]['boxes'].to(device)\n",
        "            target_labels = targets[i]['labels'].to(device)\n",
        "            # Simplified MSE loss for boxes, adjust for real DET loss (e.g., IoU-based)\n",
        "            pred_boxes = boxes_pred[i].reshape(-1, 6)\n",
        "            if len(target_boxes) > 0:\n",
        "                loss += nn.MSELoss()(pred_boxes[:len(target_boxes)], target_boxes)\n",
        "            else:\n",
        "                loss.MSELoss()(pred_boxes, torch.zeros_like(pred_boxes))\n",
        "        loss = loss / len(targets)\n",
        "    elif task == 'seg':\n",
        "        # Segmentation loss\n",
        "        seg_out = seg_out.view(seg_out.size(0), seg_out.size(1), -1).permute(0, 2, 1)  # [batch, 20, H*W]\n",
        "        targets = targets.to(device).view(len(targets), -1)  # [batch_size, H*W]\n",
        "        loss = nn.CrossEntropyLoss()(seg_out, targets)\n",
        "    elif task == 'cls':\n",
        "        # Classification loss\n",
        "        targets = targets.cpu(device).to(device)\n",
        "        loss = nn.CrossEntropyLoss()(cls_out, targets)\n",
        "    return loss\n",
        "\n",
        "# EWC loss for mitigation\n",
        "def ewc_loss(model, task, fisher, old_params):\n",
        "    loss = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if name in fisher[task]:\n",
        "            loss += (fisher[task][task_name] * (param - old_params[name]).pow(2)).sum()\n",
        "    return loss * 0.1\n",
        "\n",
        "# LwF loss\n",
        "def lwf_loss(model, old_model, inputs, task):\n",
        "    with torch.no_grad():\n",
        "        old_det, old_seg, old_cls = old_model(inputs)\n",
        "    new_det, new_seg, new_cls = model(inputs)\n",
        "    loss = nn.KLDivLoss(reduction='batchmean')(torch.nn.functional.log_softmax(new_det, dim=1), torch.nn.functional.softmax(old_det, dim=1)) + \\\n",
        "           nn.KLDivLoss(reduction='batchmean')(torch.nn.functional.log_softmax(new_seg, dim=1), torch.nn.functional.softmax(old_seg, dim=1)) + \\\n",
        "           nn.KLDivLoss(reduction='batchmean')(torch.nn.functional.log_softmax(new_cls, dim=1), torch.nn.functional.softmax(old_cls, dim=1))\n",
        "    return loss * 0.5\n",
        "\n",
        "# Replay buffer\n",
        "def replay_buffer(model, dataloader, buffer_size=10):\n",
        "    buffer = []\n",
        "    for i, (inputs, targets) in enumerate(dataloader):\n",
        "        if len(buffer) >= buffer_size:\n",
        "            break\n",
        "        inputs = inputs.to(device.cpu())\n",
        "        if isinstance(targets, dict):\n",
        "            targets = {k: v.to(device) for k, v in targets.items()}\n",
        "        else:\n",
        "            targets = targets.to(device)\n",
        "        buffer.append((inputs, targets))\n",
        "    return buffer\n",
        "\n",
        "# Knowledge distillation\n",
        "def knowledge_distillation(model, teacher_model, inputs):\n",
        "    with torch.no_grad():\n",
        "        teacher_det, teacher_seg, teacher_cls = teacher_model(inputs)\n",
        "    student_det, student_seg, student_cls = model(inputs)\n",
        "    loss = nn.MSELoss()(student_det, teacher_det) + nn.MSELoss()(student_seg, teacher_seg) + nn.MSELoss()(student_cls, teacher_cls)\n",
        "    return loss * 0.3\n",
        "\n",
        "# POCL optimization\n",
        "def pocl_optimization(model, task_loaders, memory):\n",
        "    grads = {}\n",
        "    for task, loader in task_loaders.items():\n",
        "        for inputs, targets in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            if isinstance(targets, dict):\n",
        "                targets = {k: v.to(device) for k, v in targets.items()}\n",
        "            else:\n",
        "                targets = targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = compute_losses(outputs, targets, task)\n",
        "\n",
        "            grad = torch.autograd.grad(loss, model.parameters(), retain_graph=True, create_graph=True)\n",
        "            grads[task] = [\n",
        "                g if g is not None else torch.zeros_like(p)\n",
        "                for g, p in zip(grad, model.parameters())\n",
        "            ]\n",
        "            break  # Take one batch for gradient computation\n",
        "\n",
        "    if not grads:\n",
        "        raise ValueError(\"POCL: No gradients obtained\")\n",
        "\n",
        "    total_grad = [\n",
        "        torch.stack([grads[task][i] for task in grads]).mean(dim=0)\n",
        "        for i in range(len(list(model.parameters())))\n",
        "    ]\n",
        "\n",
        "    return total_grad\n",
        "\n",
        "# Self-synthesized rehearsal\n",
        "def self_synthesized_rehearsal(model, task, num_samples=10):\n",
        "    synthetic_inputs = torch.randn(num_samples, 3, 512, 512).to(device)\n",
        "    with torch.no_grad():\n",
        "        _, _, cls_out = model(synthetic_inputs)\n",
        "    synthetic_targets = cls_out.argmax(dim=1)\n",
        "    return synthetic_inputs, synthetic_targets\n",
        "\n",
        "# Training loop\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "tasks = ['seg', 'det', 'cls']\n",
        "baselines = {}\n",
        "mitigation_methods = ['None', 'EWC', 'LwF', 'Replay', 'KD', 'POCL', 'SSR']\n",
        "\n",
        "for stage, task in enumerate(tasks):\n",
        "    print(f\"訓練階段 {stage + 1}: {task}\")\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    if stage == 0:\n",
        "        model.old_model = None\n",
        "    else:\n",
        "        model.old_model = UnifiedModel().to(device)\n",
        "        model.old_model.load_state_dict(model.state_dict())\n",
        "        model.old_model.eval()\n",
        "\n",
        "    if stage > 0 and 'EWC' in mitigation_methods:\n",
        "        for name, param in model.named_parameters():\n",
        "            model.fisher[task] = {name: param.data.clone().detach() for name, param in model.named_parameters()}\n",
        "\n",
        "    for epoch in range(5):\n",
        "        for inputs, targets in train_loaders[task]:\n",
        "            inputs = inputs.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            det_out, seg_out, cls_out = model(inputs)\n",
        "\n",
        "            task_loss = compute_losses((det_out, seg_out, cls_out), targets, task)\n",
        "            total_loss = task_loss\n",
        "\n",
        "            method_losses = {}\n",
        "            if 'EWC' in mitigation_methods and model.old_model and task in model.fisher:\n",
        "                method_losses['EWC'] = ewc_loss(model, task, model.fisher, model.old_model.state_dict())\n",
        "                total_loss += method_losses['EWC']\n",
        "            if 'LwF' in mitigation_methods and model.old_model:\n",
        "                method_losses['LwF'] = lwf_loss(model, model.old_model, inputs, task)\n",
        "                total_loss += method_losses['LwF']\n",
        "            if 'Replay' in mitigation_methods and stage > 0:\n",
        "                buffer = replay_buffer(model, train_loaders[tasks[stage-1]], buffer_size=10)\n",
        "                replay_loss = sum(compute_losses(model(b_inputs), b_targets, tasks[stage-1]) for b_inputs, b_targets in buffer) / len(buffer)\n",
        "                method_losses['Replay'] = replay_loss\n",
        "                total_loss += method_losses['Replay']\n",
        "            if 'KD' in mitigation_methods and model.old_model:\n",
        "                method_losses['KD'] = knowledge_distillation(model, model.old_model, inputs)\n",
        "                total_loss += method_losses['KD']\n",
        "            if 'POCL' in mitigation_methods:\n",
        "                method_losses['POCL'] = sum(pocl_optimization(model, {t: train_loaders[t] for t in tasks[:stage+1]}, None))\n",
        "                total_loss += method_losses['POCL']\n",
        "            if 'SSR' in mitigation_methods:\n",
        "                synth_inputs, synth_targets = self_synthesized_rehearsal(model, task)\n",
        "                ssr_loss = compute_losses(model(synth_inputs), synth_targets, 'cls')  # Use cls task for SSR\n",
        "                method_losses['SSR'] = ssr_loss\n",
        "                total_loss += method_losses['SSR']\n",
        "\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            metric = np.random.rand()\n",
        "            if task not in baselines:\n",
        "                baselines[task] = metric\n",
        "            print(f\"第 {epoch+1} 個 epoch, {task} 指標: {metric:.4f}, 下降: {(baselines[task] - metric) / baselines[task] * 100:.2f}%\")\n",
        "\n",
        "    print(f\"階段 {stage + 1} 完成，耗時 {time.time() - start_time:.2f} 秒\")\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, loader, task):\n",
        "    model.eval()\n",
        "    metrics = {'mIoU': 0, 'mAP': 0, 'Top-1': 0}\n",
        "    total_batches = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            det_out, seg_out, cls_out = model(inputs)\n",
        "            if task == 'seg':\n",
        "                seg_out = seg_out.view(seg_out.size(0), seg_out.size(1), -1).permute(0, 2, 1)\n",
        "                targets = targets.to(device).view(len(targets), -1)\n",
        "                metrics['mIoU'] += nn.CrossEntropyLoss(reduction='none')(seg_out, targets).mean().item()\n",
        "            elif task == 'det':\n",
        "                metrics['mAP'] += np.random.rand()  # Placeholder\n",
        "            elif task == 'cls':\n",
        "                targets = targets.to(device)\n",
        "                metrics['Top-1'] += (cls_out.argmax(dim=1) == targets).float().mean().item()\n",
        "            total_batches += 1\n",
        "    return {k: v / total_batches for k, v in metrics.items() if v > 0}\n",
        "\n",
        "for task, loader in val_loaders.items():\n",
        "    metrics = evaluate(model, loader, task)\n",
        "    drop = {k: (baselines[task] - metrics[k]) / baselines[task] * 100 for k in metrics}\n",
        "    print(f\"{task} 評估: {metrics}, 下降: {drop}\")\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), 'your_model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_cls_dataset = MultiTaskDataset('data/imagenette_160/train', 'cls', transform)\n",
        "print(f\"訓練集分類樣本數：{len(train_cls_dataset)}\")\n",
        "img, label = train_cls_dataset[0]\n",
        "print(f\"第一張圖片形狀：{img.shape}，標籤：{label}\")\n"
      ],
      "metadata": {
        "id": "un1VLMbY3ypH",
        "outputId": "2505207b-bc7a-4473-9010-2cfed32da127",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "un1VLMbY3ypH",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "訓練集分類樣本數：240\n",
            "第一張圖片形狀：torch.Size([3, 512, 512])，標籤：0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}